handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/tweets/01292020/economy01292020.json"
current_day = fromJSON(file) %>% as.data.frame()
current_day = current_day[1:2000,]
users_unique = as.character(unique(current_day$tweets.screen_name))
df_userbots <- data.frame()
for(user_idx in 1:length(users_unique)){
if(user_idx %% 100 == 0){
cat("Checking user account ", users_unique[user_idx],
", number ", user_idx, "\n", sep = "")
}
tryCatch({
tmp_userlist <- bom$check_account(users_unique[user_idx])
tmp_user_df <- as.data.frame(tmp_userlist)
tmp_user_df <- tmp_user_df %>%
dplyr::mutate_if(is.factor, as.character)
df_userbots <- dplyr::bind_rows(df_userbots, tmp_user_df)
}, error = function(e) print(e))
}
bots <- dplyr::filter(df_userbots, cap.universal > 0.43)
n <- length(current_day$tweets.screen_name)
prop_convo_level_bots <- (sum(current_day$tweets.screen_name %in% bots$user.screen_name) / n)
prop_convo_level_bots
nbots <- length(bots$user.screen_name)
n <- length(unique(current_day$tweets.screen_name))
prop_user_level_bots <- (nbots / n)
prop_user_level_bots
diss_botscan_results_economy_012920 = df_userbots
save(diss_botscan_results_economy_012920, file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/botscan/01292020/economy_botscan.RData")
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
current_day_bots_removed = subset(current_day, !(current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots_removed %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment
current_day_bots_removed_no_verifieds = subset(current_day_bots_removed, tweets.verified == FALSE)
handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/tweets/01302020/trump01302020.json"
current_day = fromJSON(file) %>% as.data.frame()
current_day = current_day[1:2000,]
users_unique = as.character(unique(current_day$tweets.screen_name))
df_userbots <- data.frame()
for(user_idx in 1:length(users_unique)){
if(user_idx %% 100 == 0){
cat("Checking user account ", users_unique[user_idx],
", number ", user_idx, "\n", sep = "")
}
tryCatch({
tmp_userlist <- bom$check_account(users_unique[user_idx])
tmp_user_df <- as.data.frame(tmp_userlist)
tmp_user_df <- tmp_user_df %>%
dplyr::mutate_if(is.factor, as.character)
df_userbots <- dplyr::bind_rows(df_userbots, tmp_user_df)
}, error = function(e) print(e))
}
bots <- dplyr::filter(df_userbots, cap.universal > 0.43)
n <- length(current_day$tweets.screen_name)
prop_convo_level_bots <- (sum(current_day$tweets.screen_name %in% bots$user.screen_name) / n)
prop_convo_level_bots
nbots <- length(bots$user.screen_name)
n <- length(unique(current_day$tweets.screen_name))
prop_user_level_bots <- (nbots / n)
prop_user_level_bots
diss_botscan_results_trump_013020 = df_userbots
save(diss_botscan_results_trump_013020, file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/botscan/01302020/trump_botscan.RData")
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
current_day_bots_removed = subset(current_day, !(current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots_removed %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment
current_day_bots_removed_no_verifieds = subset(current_day_bots_removed, tweets.verified == FALSE)
handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/tweets/01302020/economy01302020.json"
current_day = fromJSON(file) %>% as.data.frame()
current_day = current_day[1:2000,]
users_unique = as.character(unique(current_day$tweets.screen_name))
df_userbots <- data.frame()
for(user_idx in 1:length(users_unique)){
if(user_idx %% 100 == 0){
cat("Checking user account ", users_unique[user_idx],
", number ", user_idx, "\n", sep = "")
}
tryCatch({
tmp_userlist <- bom$check_account(users_unique[user_idx])
tmp_user_df <- as.data.frame(tmp_userlist)
tmp_user_df <- tmp_user_df %>%
dplyr::mutate_if(is.factor, as.character)
df_userbots <- dplyr::bind_rows(df_userbots, tmp_user_df)
}, error = function(e) print(e))
}
bots <- dplyr::filter(df_userbots, cap.universal > 0.43)
n <- length(current_day$tweets.screen_name)
prop_convo_level_bots <- (sum(current_day$tweets.screen_name %in% bots$user.screen_name) / n)
prop_convo_level_bots
nbots <- length(bots$user.screen_name)
n <- length(unique(current_day$tweets.screen_name))
prop_user_level_bots <- (nbots / n)
prop_user_level_bots
diss_botscan_results_economy_013020 = df_userbots
save(diss_botscan_results_economy_013020, file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/botscan/01302020/economy_botscan.RData")
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
current_day_bots_removed = subset(current_day, !(current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots_removed %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment
current_day_bots_removed_no_verifieds = subset(current_day_bots_removed, tweets.verified == FALSE)
handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/tweets/01312020/trump01312020.json"
current_day = fromJSON(file) %>% as.data.frame()
current_day = current_day[1:2000,]
users_unique = as.character(unique(current_day$tweets.screen_name))
df_userbots <- data.frame()
for(user_idx in 1:length(users_unique)){
if(user_idx %% 100 == 0){
cat("Checking user account ", users_unique[user_idx],
", number ", user_idx, "\n", sep = "")
}
tryCatch({
tmp_userlist <- bom$check_account(users_unique[user_idx])
tmp_user_df <- as.data.frame(tmp_userlist)
tmp_user_df <- tmp_user_df %>%
dplyr::mutate_if(is.factor, as.character)
df_userbots <- dplyr::bind_rows(df_userbots, tmp_user_df)
}, error = function(e) print(e))
}
bots <- dplyr::filter(df_userbots, cap.universal > 0.43)
n <- length(current_day$tweets.screen_name)
prop_convo_level_bots <- (sum(current_day$tweets.screen_name %in% bots$user.screen_name) / n)
prop_convo_level_bots
nbots <- length(bots$user.screen_name)
n <- length(unique(current_day$tweets.screen_name))
prop_user_level_bots <- (nbots / n)
prop_user_level_bots
diss_botscan_results_trump_013120 = df_userbots
save(diss_botscan_results_trump_013120, file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/botscan/01312020/trump_botscan.RData")
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
current_day_bots_removed = subset(current_day, !(current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots_removed %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment
current_day_bots_removed_no_verifieds = subset(current_day_bots_removed, tweets.verified == FALSE)
handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/tweets/01312020/economy01312020.json"
current_day = fromJSON(file) %>% as.data.frame()
current_day = current_day[1:2000,]
users_unique = as.character(unique(current_day$tweets.screen_name))
df_userbots <- data.frame()
for(user_idx in 1:length(users_unique)){
if(user_idx %% 100 == 0){
cat("Checking user account ", users_unique[user_idx],
", number ", user_idx, "\n", sep = "")
}
tryCatch({
tmp_userlist <- bom$check_account(users_unique[user_idx])
tmp_user_df <- as.data.frame(tmp_userlist)
tmp_user_df <- tmp_user_df %>%
dplyr::mutate_if(is.factor, as.character)
df_userbots <- dplyr::bind_rows(df_userbots, tmp_user_df)
}, error = function(e) print(e))
}
bots <- dplyr::filter(df_userbots, cap.universal > 0.43)
n <- length(current_day$tweets.screen_name)
prop_convo_level_bots <- (sum(current_day$tweets.screen_name %in% bots$user.screen_name) / n)
prop_convo_level_bots
nbots <- length(bots$user.screen_name)
n <- length(unique(current_day$tweets.screen_name))
prop_user_level_bots <- (nbots / n)
prop_user_level_bots
diss_botscan_results_economy_013120 = df_userbots
save(diss_botscan_results_economy_013120, file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/botscan/01312020/economy_botscan.RData")
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
current_day_bots_removed = subset(current_day, !(current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots_removed %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment
current_day_bots_removed_no_verifieds = subset(current_day_bots_removed, tweets.verified == FALSE)
handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/tweets/02012020/trump02012020.json"
current_day = fromJSON(file) %>% as.data.frame()
current_day = current_day[1:2000,]
users_unique = as.character(unique(current_day$tweets.screen_name))
df_userbots <- data.frame()
for(user_idx in 1:length(users_unique)){
if(user_idx %% 100 == 0){
cat("Checking user account ", users_unique[user_idx],
", number ", user_idx, "\n", sep = "")
}
tryCatch({
tmp_userlist <- bom$check_account(users_unique[user_idx])
tmp_user_df <- as.data.frame(tmp_userlist)
tmp_user_df <- tmp_user_df %>%
dplyr::mutate_if(is.factor, as.character)
df_userbots <- dplyr::bind_rows(df_userbots, tmp_user_df)
}, error = function(e) print(e))
}
bots <- dplyr::filter(df_userbots, cap.universal > 0.43)
n <- length(current_day$tweets.screen_name)
prop_convo_level_bots <- (sum(current_day$tweets.screen_name %in% bots$user.screen_name) / n)
prop_convo_level_bots
nbots <- length(bots$user.screen_name)
n <- length(unique(current_day$tweets.screen_name))
prop_user_level_bots <- (nbots / n)
prop_user_level_bots
diss_botscan_results_trump_020120 = df_userbots
save(diss_botscan_results_trump_020120, file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/botscan/02012020/trump_botscan.RData")
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
current_day_bots_removed = subset(current_day, !(current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots_removed %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment
current_day_bots_removed_no_verifieds = subset(current_day_bots_removed, tweets.verified == FALSE)
handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/tweets/02012020/economy02012020.json"
current_day = fromJSON(file) %>% as.data.frame()
current_day = current_day[1:2000,]
users_unique = as.character(unique(current_day$tweets.screen_name))
df_userbots <- data.frame()
for(user_idx in 1:length(users_unique)){
if(user_idx %% 100 == 0){
cat("Checking user account ", users_unique[user_idx],
", number ", user_idx, "\n", sep = "")
}
tryCatch({
tmp_userlist <- bom$check_account(users_unique[user_idx])
tmp_user_df <- as.data.frame(tmp_userlist)
tmp_user_df <- tmp_user_df %>%
dplyr::mutate_if(is.factor, as.character)
df_userbots <- dplyr::bind_rows(df_userbots, tmp_user_df)
}, error = function(e) print(e))
}
bots <- dplyr::filter(df_userbots, cap.universal > 0.43)
n <- length(current_day$tweets.screen_name)
prop_convo_level_bots <- (sum(current_day$tweets.screen_name %in% bots$user.screen_name) / n)
prop_convo_level_bots
nbots <- length(bots$user.screen_name)
n <- length(unique(current_day$tweets.screen_name))
prop_user_level_bots <- (nbots / n)
prop_user_level_bots
diss_botscan_results_economy_020120 = df_userbots
save(diss_botscan_results_economy_020120, file = "D:/Users/Kurt/Documents/Research/Dissertation/Data/botscan/02012020/economy_botscan.RData")
handles_text = current_day %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
current_day_corpus_sentiment = mean(current_day_sentiment_scores$ave_sentiment)
current_day_corpus_sentiment
current_day_bots_removed = subset(current_day, !(current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots_removed %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment
current_day_bots_removed_no_verifieds = subset(current_day_bots_removed, tweets.verified == FALSE)
handles_text = current_day_bots_removed_no_verifieds %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_individual_sentiment_no_verifieds = mean(sentiment_by_individual$individual_sentiment)
current_day_individual_sentiment_no_verifieds
current_day_bots = subset(current_day, (current_day$tweets.screen_name %in% bots$user.screen_name))
handles_text = current_day_bots %>% select(5, 6)
tweet_text_sentences = get_sentences(handles_text$tweets.text)
current_day_sentiment_scores = sentiment_by(tweet_text_sentences) %>%
mutate(tweets.screen_name = handles_text$tweets.screen_name) %>%
select(-element_id)
current_day_sentiment_scores = current_day_sentiment_scores[,c(4,3,2,1)]
sentiment_by_individual = current_day_sentiment_scores %>% group_by(tweets.screen_name) %>%
summarise(individual_sentiment = mean(ave_sentiment))
current_day_bot_sentiment = mean(sentiment_by_individual$individual_sentiment)
current_day_bot_sentiment
